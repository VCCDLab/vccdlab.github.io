---
---

@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@article{2024-TPAMI-CIAVVR,
  title={Hierarchical Augmentation and Distillation for Class Incremental Audio-Visual Video Recognition},
  author={Zuo, Yukun and Yao, Hantao and Zhuang, Liansheng and Xu, Changsheng},
  abstract={Audio-visual video recognition (AVVR) aims to integrate audio and visual clues to categorize videos accurately. While existing methods train AVVR models using provided datasets and achieve satisfactory results, they struggle to retain historical class knowledge when confronted with new classes in real-world situations. Currently, there are no dedicated methods for addressing this problem, so this paper concentrates on exploring Class Incremental Audio-Visual Video Recognition (CIAVVR). For CIAVVR, since both stored data and learned model of past classes contain historical knowledge, the core challenge is how to capture past data knowledge and past model knowledge to prevent catastrophic forgetting. As audio-visual data and model inherently contain hierarchical structures, i.e., model embodies low-level and high-level semantic information, and data comprises snippet-level, video-level, and distribution-level spatial information, it is essential to fully exploit the hierarchical data structure for data knowledge preservation and hierarchical model structure for model knowledge preservation. However, current image class incremental learning methods do not explicitly consider these hierarchical structures in model and data. Consequently, we introduce Hierarchical Augmentation and Distillation (HAD), which comprises the Hierarchical Augmentation Module (HAM) and Hierarchical Distillation Module (HDM) to efficiently utilize the hierarchical structure of data and models, respectively. Specifically, HAM implements a novel augmentation strategy, segmental feature augmentation, to preserve hierarchical model knowledge. Meanwhile, HDM introduces newly designed hierarchical (video-distribution) logical distillation and hierarchical (snippet-video) correlative distillation to capture and maintain the hierarchical intra-sample knowledge of each data and the hierarchical inter-sample knowledge between data, respectively. Evaluations on four benchmarks (AVE, AVK-100, AVK-200, and AVK-400) demonstrate that the proposed HAD effectively captures hierarchical information in both data and models, resulting in better preservation of historical class knowledge and improved performance. Furthermore, we provide a theoretical analysis to support the necessity of the segmental feature augmentation strategy.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={},
  number={},
  pages={1-15},
  year={2024},
  pdf={2024-TPMAI-CIAVVR.pdf},
  publisher={IEEE},
  bibtex_show={true},
  doi={10.1109/TPAMI.2024.3387946},
  html={https://ieeexplore.ieee.org/document/10497880},
  url={#},   
  selected = {true}
}

@inproceedings{2024-IJCAI-SER,
  title={Learning Label Dependencies for Visual Information Extraction},
  author={Yao, Minghong and Zhuang, Liansheng and Li, Houqiang and Wei, Jiuchang},
  abstract={#},
  booktitle={International Joint Conference on Artificial Intelligence},
  pages ={#},
  year = {2024},
  month = {August},
  address = {Jeju},
  abbr={Vision},
  bibtex_show={false},
  doi={#},
  html={#},
  url={#},   
  selected={false}
}

@inproceedings{2024-WWW-FDM,
  title={Fact Embedding through Diffusion Model for Knowledge Graph Completion},
  author={Long, Xiao and Zhuang, Liansheng and Li, Aodi and Li, Houqiang and Wang, Jiuchang},
  booktitle={The 2024 ACM Web Conference},
  pages ={#},
  year = {2024},
  month = {May},
  address = {Singapore},
  publisher = {ACM},
  pdf={2024-WWW-FDM.pdf},
  abbr={Vision},
  bibtex_show={true},
  doi={#},
  html={#},
  url={#},   
  selected={true}
}

@article{2024-TIP-dPGM,
  title={A Robust Framework for One-shot Key Information Extraction via Deep Partial Graph Matching},
  author={Yao, Minghong and Liu, Zhiguang and Zhuang, Liansheng and Wang, Liangwei and Li, Houqiang},
  abstract={Text field labelling plays a key role in Key Information Extraction (KIE) from structured document images. However, existing methods ignore the field drift and outlier problems, which limit their performance and make them less robust. This paper casts the text field labelling problem into a partial graph matching problem and proposes an end-to-end trainable framework called Deep Partial Graph Matching (dPGM) for the one-shot KIE task. It represents each document as a graph and estimates the correspondence between text fields from different documents by maximizing the graph similarity of different documents. Our framework obtains a strict one-to-one correspondence by adopting a combinatorial solver module with an extra one-to-(at most)-one mapping constraint to do the exact graph matching, which leads to the robustness of the field drift problem and the outlier problem. Finally, a large one-shot KIE dataset named DKIE is collected and annotated to promote research of the KIE task. This dataset will be released to the research and industry communities. Extensive experiments on both the public and our new DKIE datasets show that our method can achieve state-of-the-art performance and is more robust than existing methods.},
  journal={IEEE Transactions on Image Processing},
  volume={33},
  number={#},
  pages={1070-1079},
  year={2024},
  pdf={2024-TIP-dPGM.pdf},
  publisher={IEEE},
  abbr={Vision},
  bibtex_show={},
  doi={10.1109/TIP.2024.3357251},
  html={https://ieeexplore.ieee.org/document/10416209},
  url={#},   
  selected={false}
}


@inproceedings{2024-AAAI-KGDM,
  title={KGDM: A Diffusion Model to Capture Multiple Relation Semantics for Knowledge Graph Embedding},
  author={Long, Xiao and Zhuang, Liansheng and Li, Aodi and Wang, Jiuchang and Li, Houqiang and Wang, Shafei},
  abstract={nowledge graph embedding (KGE) is an efficient and scalable method for knowledge graph completion. However, most existing KGE methods suffer from the challenge of multiple relation semantics, which often degrades their performance. This is because most KGE methods learn fixed continuous vectors for entities (relations) and make deterministic entity predictions to complete the knowledge graph, which hardly captures multiple relation semantics. To tackle this issue, previous works try to learn complex probabilistic embeddings instead of fixed embeddings but suffer from heavy computational complexity. In contrast, this paper proposes a simple yet efficient framework namely the Knowledge Graph Diffusion Model (KGDM) to capture the multiple relation semantics in prediction. Its key idea is to cast the problem of entity prediction into conditional entity generation. Specifically, KGDM estimates the probabilistic distribution of target entities in prediction through Denoising Diffusion Probabilistic Models (DDPM). To bridge the gap between continuous diffusion models and discrete KGs, two learnable embedding functions are defined to map entities and relation to continuous vectors. To consider connectivity patterns of KGs, a Conditional Entity Denoiser model is introduced to generate target entities conditioned on given entities and relations. Extensive experiments demonstrate that KGDM significantly outperforms existing state-of-the-art methods in three benchmark datasets.},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={8},
  pages ={8850-8858},
  year = {2024},
  month = {February},
  address = {VANCOUVER, CANADA},
  pdf ={2024-AAAI-KGDM.pdf},
  publisher={AAAI},
  abbr={Vision},
  bibtex_show={true},
  doi={https://doi.org/10.1609/aaai.v38i8.28732},
  html={https://ojs.aaai.org/index.php/AAAI/article/view/28732},
  url={#},   
  selected={true}
}

@inproceedings{2023-MMAsia-PbGaR,
  title={Learning a Robust Model with Pseudo Boundaries for Noisy Temporal Action Localization},
  author={Yuan, Xinyi and Zhuang},
  abstract={Temporal Action Localization (TAL) aims to locate starting and ending times of actions and recognize categories in untrimmed videos. Significant progress has been made in developing deep models for TAL. The success of previous methods relies on large-scale training data with precise boundary annotations. However, fully accurate annotations are unpractical to be obtained due to the ambiguities of the action boundaries and the crowd-sourcing labeling process, leading to a degradation in performance. In this work, we take the first step into learning with inaccurate boundaries in TAL tasks. Motivated by the fact that inaccurate boundary annotations harm localization precision more than classification accuracy, we propose to use classification as a guidance signal to improve localization precision. Specifically, we introduce a pseudo-boundary generation and refinement method (PbGaR). PbGaR first treats each action segment as a bag of instances to select the instances with more accurate boundaries for training. Then these boundaries are refined via two strategies for higher quality. The proposed method significantly alleviates the degraded performance of TAL models under inaccurate boundaries. Extensive experiments on two popular datasets demonstrate the effectiveness of our method.},
  booktitle={Proceedings of the 5th ACM International Conference on Multimedia in Asia},
  number={81},
  pages ={1-7},
  year = {2023},
  month = {December},
  address = {Taiwan, China},
  pdf ={2023-MMAsia-PbGaR.pdf},
  abbr={Vision},
  bibtex_show={true},
  doi={10.1145/3595916.3626455},
  html={https://dl.acm.org/doi/10.1145/3595916.3626455},
  url={#},   
  selected={false}
}

@inproceedings{2023-MM-CALayoutDM,
  title={Two-stage Content-Aware Layout Generation for Poster Designs},
  author={Chai, Shang and Zhuang, Liansheng and Yan, Fengying and Zhou, Zihan},
  abstract={Automatic layout generation models can generate numerous design layouts in a few seconds, which significantly reduces the amount of repetitive work for designers. However, most of these models consider the layout generation task as arranging layout elements with different attributes on a blank canvas, thus struggle to handle the case when an image is used as the layout background. Additionally, existing layout generation models often fail to incorporate explicit aesthetic principles such as alignment and non-overlap, and neglect implicit aesthetic principles which are hard to model. To address these issues, this paper proposes a two-stage content-aware layout generation framework for poster layout generation. Our framework consists of an aesthetics-conditioned layout generation module and a layout ranking module. The diffusion model based layout generation module utilizes an aesthetics-guided layout denoising process to sample layout proposals that meet explicit aesthetic constraints. The Auto-Encoder based layout ranking module then measures the distance between those proposals and real designs to determine the layout that best meets implicit aesthetic principles. Quantitative and qualitative experiments demonstrate that our method outperforms state-of-the-art content-aware layout generation models.},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages ={8415-8423},
  year = {2023},
  month = {Oct.},
  address = {Ottawa, Canada},
  pdf ={2023-MM-CALayoutDM.pdf},
  abbr={Vision},
  bibtex_show={true},
  doi={10.1145/3581783.3612275},
  html={https://dl.acm.org/doi/10.1145/3581783.3612275},
  url={#},   
  selected={false}
}

@inproceedings{2023-MM-OSTAL,
  title={Learning Generalized Representation for Open Set Temporal Action Localization},
  author={Hu, Junshan and Zhuang, Liansheng and Dong, Weisong and Ge, Shiming and Wang, Shafei},
  abstract={Open-set Temporal Action Localization (OSTAL) is a critical and challenging task that aims to recognize and temporally localize human actions in untrimmed videos in open word scenarios. The main challenge in this task is the knowledge transfer from known actions to unknown actions. However, existing methods utilize limited training data and overparameterized deep neural network, which have poor generalization. This paper proposes a novel Generalized OSTAL model (namely GOTAL) to learn generalized representations of actions. GOTAL utilizes a Transformer network to model actions and a open-set detection head to perform action localization and recognition. Benefitting from Transformer's temporal modeling capabilities, GOTAL facilitates the extraction of human motion information from videos to mitigate the effects of irrelevant background data. Furthermore, a sharpness minimization algorithm is used to learn the network parameters of GOTAL, which facilitates the convergence of network parameters towards flatter minima by simultaneously minimizing the training loss value and sharpness of the loss plane. The collaboration of the above components significantly enhances the generalization of the representation. Experimental results demonstrate that GOTAL achieves the state-of-the-art performance on THUMOS14 and ActivityNet1.3 benchmarks, confirming the effectiveness of our proposed method.},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages ={1987-1996},
  year = {2023},
  month = {Oct.},
  address = {Ottawa, Canada},
  pdf ={2023-MM-OSTAL.pdf},
  abbr={Vision},
  bibtex_show={true},
  doi={10.1145/3581783.3612278},
  html={https://dl.acm.org/doi/10.1145/3581783.3612278},
  url={#},   
  selected={false}
}

@inproceedings{2023-CVPR-LayoutDM,
  title={LayoutDM: Transformer-based Diffusion Model for Conditional Layout Generation},
  author={Chai, Shang and Zhuang, Liansheng and Yan, Fengying},
  abstract={Automatic layout generation that can synthesize high-quality layouts is an important tool for graphic design in many applications. Though existing methods based on generative models such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) have progressed, they still leave much room for improving the quality and diversity of the results. Inspired by the recent success of diffusion models in generating high-quality images, this paper explores their potential for conditional layout generation and proposes Transformer-based Layout Diffusion Model (LayoutDM) by instantiating the conditional denoising diffusion probabilistic model (DDPM) with a purely transformer-based architecture. Instead of using convolutional neural networks, a transformer-based conditional Layout Denoiser is proposed to learn the reverse diffusion process to generate samples from noised layout data. Benefitting from both transformer and DDPM, our LayoutDM is of desired properties such as high-quality generation, strong sample diversity, faithful distribution coverage, and stationary training in comparison to GANs and VAEs. Quantitative and qualitative experimental results show that our method outperforms state-of-the-art generative models in terms of quality and diversity.},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages ={18349-18358},
  year = {2023},
  month = {June},
  address = {Vancouver, BC, Canada},
  pdf ={2023-CVPR-LayoutDM.pdf},
  abbr={Vision},
  bibtex_show={true},
  doi={10.1109/CVPR52729.2023.01760},
  html={https://ieeexplore.ieee.org/document/10204668},
  url={#},   
  selected={false}
}

@inproceedings{2023-IJCNN-MAPF,
  title={Curriculum Learning Based Multi-Agent Path Finding for Complex Enviroments},
  author={Zhao, Cheng and Zhuang, Liansheng and Huang, Yihong and Liu, Haonan},
  abstract={Multi-agent reinforcement learning (MARL) is a promising tool to solve the Multi-Agent Path Finding (MAPF) task, which aims to find conflict-free paths for multiple agents, one for each agent, from a start position to a goal position. It uses global information to learn a mechanism for cooperation among agents by maximising the cumulative team rewards, which are often very sparse. However, the sparsity of rewards implies that agents have to blindly explore all possible paths, which makes MARL methods difficult to converge in complex environments. To address this issue, this paper proposes a novel Curriculum based Path-finding Learning (CPL) under the framework of curriculum learning, which allows agents to start with simple skills and to learn cooperative strategies stage-by-stage for more efficient training. Specifically, CPL divides the training process into three stages and speeds up the learning by changing the difficulty of the tasks from easy to hard. Experiments on random obstacle grid worlds show that our proposed method performs significantly better in terms of success rate and makespan than state-of-the-art learning-based methods.},
  booktitle={2023 International Joint Conference on Neural Networks},
  pages ={1-8},
  year = {2023},
  month = {June},
  address = {Gold Coast, Australia},
  pdf ={2023-IJCNN-MAPF.pdf},
  abbr={Vision},
  bibtex_show={false},
  doi={10.1109/IJCNN54540.2023.10191932},
  html={https://ieeexplore.ieee.org/document/10191932},
  url={},  
  selected={false}
}

@inproceedings{2023-IJCNN-BSPT,
  title={Bayesian Sharpness-Aware Prompt Tuning for Cross-Domain Few-Shot Learning},
  author={Fan, Shuo and Zhuang, Liansheng and Li, Aodi},
  abstract={Few-shot learning aims to learn a classifier to recognize novel classes with only few labeled images in each class. Fine-tuning is a promising tool to solve the few-shot learning problem, which pre-trains a large-scale model on source domains and then adapts it to target domains. However, existing methods have poor generalization when encountering the domain-shifting problem in the cross-domain scenario. Inspired by recent advances on domain generalization and prompt-based tuning methods, this paper proposes Bayesian Sharpness-Aware Prompt Tuning (BSAPT) for the cross-domain few-shot learning task. Instead of learning deterministic prompts like existing methods, our BSAPT learns a weight distribution over prompts to model the uncertainty caused by limited training data and resist overfitting. To improve the generalization ability, our BSAPT seeks the prompts which lie in neighborhoods having uniformly low loss by simultaneously minimizing the training loss value and loss sharpness. Benefiting from deterministic pre-trained training and Bayesian inference, our BSAPT has better generalization ability and less overfitting than existing fine-tuning methods. Extensive experiments on public datasets show that our BSAPT outperforms state-of-the-art methods and achieves new state-of-the-art performance in the cross-domain few-shot learning task.},
  booktitle={2023 International Joint Conference on Neural Networks},
  pages ={1-7},
  year = {2023},
  month = {June},
  address = {Gold Coast, Australia},
  pdf = {2023-IJCNN-BSPT.pdf},
  abbr={Vision},
  bibtex_show={true},
  doi={10.1109/IJCNN54540.2023.10191224},
  html={https://ieeexplore.ieee.org/abstract/document/10191224},
  url={#},  
  selected={false}
}


@article{2023-TMM-DSKI,
  title={Dual Structural Knowledge Interaction for Domain Adaptation},
  author={Zuo, Yukun and Yao, Hantao and Zhuang, Liansheng and Xu, Changsheng},
  abstract={Domain adaptation aims to transfer knowledge from a label-rich source domain to an unlabeled target domain. A common strategy is to assign pseudo-labels to unlabeled target samples for performing representation learning. However, most existing methods only apply the source-guided classifier to generate the source-biased pseudo-labels for self-training, leading to biased target representations. Moreover, the generated pseudo-labels ignore the manifold assumption that neighboring samples are likely to have the same labels. To address the above problem, we formulate a novel structural knowledge to assign target-oriented and manifold-guided pseudo-labels for unlabeled target samples. The structural knowledge consists of cluster-based knowledge and locality-based knowledge. The cluster-based knowledge denotes the label consistency between the target samples and the non-parametric target cluster centers, making the pseudo-labels target-oriented. The locality-based knowledge constrains the target sample and its neighbors to satisfy the manifold assumption. As the neighbors contain the source and target samples, the source and target locality-based knowledge are utilized to boost the descriptions. With the structural knowledge, we propose a novel Dual Structural Knowledge Interaction (DSKI) framework for domain adaptation. For generating aligned and discriminative features, knowledge consistency constraint and instance mutual constraint are proposed in DSKI. Evaluations on three benchmarks demonstrate the effectiveness of the Dual Structural Knowledge Interaction, e.g., 74.9%, 87.7%, and 90.8% for Office-Home, VisDa-2017, and Office-31, respectively.},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  number={#},
  pages={9057-9070},
  year={2023},
  pdf={2023-TMM-DSKI.pdf},
  publisher={IEEE},
  abbr={Vision},
  bibtex_show={true},
  doi={10.1109/TMM.2023.3245420},
  html={https://ieeexplore.ieee.org/document/10049182},
  url={#},  
  selected={false}
}

@inproceedings{2022-EMNLP-NMPQEM,
  title={Neural-based Mixture Probabilistic Query Embedding for Answering FOL queries on Knowledge Graphs},
  author={Long, Xiao and Zhuang, Liansheng and Li, Aodi and Wang, Shafei and Li, Houqiang},
  abstract={Query embedding (QE)—which aims to embed entities and first-order logical (FOL) queries in a vector space, has shown great power in answering FOL queries on knowledge graphs (KGs). Existing QE methods divide a complex query into a sequence of mini-queries according to its computation graph and perform logical operations on the answer sets of mini-queries to get answers. However, most of them assume that answer sets satisfy an individual distribution (e.g., Uniform, Beta, or Gaussian), which is often violated in real applications and limit their performance. In this paper, we propose a Neural-based Mixture Probabilistic Query Embedding Model (NMP-QEM) that encodes the answer set of each mini-query as a mixed Gaussian distribution with multiple means and covariance parameters, which can approximate any random distribution arbitrarily well in real KGs. Additionally, to overcome the difficulty in defining the closed solution of negation operation, we introduce neural-based logical operators of projection, intersection and negation for a mixed Gaussian distribution to answer all the FOL queries. Extensive experiments demonstrate that NMP-QEM significantly outperforms existing state-of-the-art methods on benchmark datasets. In NELL995, NMP-QEM achieves a 31% relative improvement over the state-of-the-art.},
  booktitle={The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)},
  pages ={3001-3013},
  year = {2022},
  month = {Dec.7-11},
  address = {Abu Dhabi, United Arab Emirates},
  pdf ={2022-EMNLP-NMPQEM.pdf},
  abbr={ACL},
  bibtex_show={true},
  doi={10.18653/v1/2022.emnlp-main.194},
  html={https://aclanthology.org/2022.emnlp-main.194/},
  url={https://aclanthology.org/2022.emnlp-main.194},  
  selected={false}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  bibtex_show={true},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  selected={true}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}
