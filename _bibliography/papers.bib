---
---

@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@article{2024-TPAMI-CIAVVR,
  title={Hierarchical Augmentation and Distillation for Class Incremental Audio-Visual Video Recognition},
  author={Zuo, Yukun and Yao, Hantao and Zhuang, Liansheng and Xu, Changsheng},
  abstract={Audio-visual video recognition (AVVR) aims to integrate audio and visual clues to categorize videos accurately. While existing methods train AVVR models using provided datasets and achieve satisfactory results, they struggle to retain historical class knowledge when confronted with new classes in real-world situations. Currently, there are no dedicated methods for addressing this problem, so this paper concentrates on exploring Class Incremental Audio-Visual Video Recognition (CIAVVR). For CIAVVR, since both stored data and learned model of past classes contain historical knowledge, the core challenge is how to capture past data knowledge and past model knowledge to prevent catastrophic forgetting. As audio-visual data and model inherently contain hierarchical structures, i.e., model embodies low-level and high-level semantic information, and data comprises snippet-level, video-level, and distribution-level spatial information, it is essential to fully exploit the hierarchical data structure for data knowledge preservation and hierarchical model structure for model knowledge preservation. However, current image class incremental learning methods do not explicitly consider these hierarchical structures in model and data. Consequently, we introduce Hierarchical Augmentation and Distillation (HAD), which comprises the Hierarchical Augmentation Module (HAM) and Hierarchical Distillation Module (HDM) to efficiently utilize the hierarchical structure of data and models, respectively. Specifically, HAM implements a novel augmentation strategy, segmental feature augmentation, to preserve hierarchical model knowledge. Meanwhile, HDM introduces newly designed hierarchical (video-distribution) logical distillation and hierarchical (snippet-video) correlative distillation to capture and maintain the hierarchical intra-sample knowledge of each data and the hierarchical inter-sample knowledge between data, respectively. Evaluations on four benchmarks (AVE, AVK-100, AVK-200, and AVK-400) demonstrate that the proposed HAD effectively captures hierarchical information in both data and models, resulting in better preservation of historical class knowledge and improved performance. Furthermore, we provide a theoretical analysis to support the necessity of the segmental feature augmentation strategy.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={},
  number={},
  pages={1-15},
  year={2024},
  pdf={2024-TPMAI-CIAVVR.pdf},
  publisher={IEEE},
  bibtex_show={true},
  doi={10.1109/TPAMI.2024.3387946},
  html={https://ieeexplore.ieee.org/document/10497880},
  url={},   
  selected = {true}
}

@inproceedings{2024-IJCAI-SER,
  title={Learning Label Dependencies for Visual Information Extraction},
  author={Yao, Minghong and Zhuang, Liansheng and Li, Houqiang and Wei, Jiuchang},
  abstract={},
  booktitle={International Joint Conference on Artificial Intelligence},
  pages ={},
  year = {2024},
  month = {},
  address = {},
  abbr={Vision},
  bibtex_show={},
  doi={},
  html={},
  url={},   
  selected={false}
}

@inproceedings{2024-WWW-FDM,
  title={Fact Embedding through Diffusion Model for Knowledge Graph Completion},
  author={Long, Xiao and Zhuang, Liansheng and Li, Aodi and Li, Houqiang and Wang, Jiuchang},
  booktitle={The 2024 ACM Web Conference},
  pages ={},
  year = {2024},
  month = {},
  address = {},
  publisher = {ACM},
  pdf={2024-WWW-FDM.pdf},
  abbr={Vision},
  bibtex_show={},
  doi={},
  html={},
  url={},   
  selected={true}
}

@article{2024-TIP-dPGM,
  title={A Robust Framework for One-shot Key Information Extraction via Deep Partial Graph Matching},
  author={Yao, Minghong and Liu, Zhiguang and Zhuang, Liansheng and Wang, Liangwei and Li, Houqiang},
  abstract={Text field labelling plays a key role in Key Information Extraction (KIE) from structured document images. However, existing methods ignore the field drift and outlier problems, which limit their performance and make them less robust. This paper casts the text field labelling problem into a partial graph matching problem and proposes an end-to-end trainable framework called Deep Partial Graph Matching (dPGM) for the one-shot KIE task. It represents each document as a graph and estimates the correspondence between text fields from different documents by maximizing the graph similarity of different documents. Our framework obtains a strict one-to-one correspondence by adopting a combinatorial solver module with an extra one-to-(at most)-one mapping constraint to do the exact graph matching, which leads to the robustness of the field drift problem and the outlier problem. Finally, a large one-shot KIE dataset named DKIE is collected and annotated to promote research of the KIE task. This dataset will be released to the research and industry communities. Extensive experiments on both the public and our new DKIE datasets show that our method can achieve state-of-the-art performance and is more robust than existing methods.},
  journal={IEEE Transactions on Image Processing},
  volume={33},
  number={},
  pages={1070-1079},
  year={2024},
  pdf={2024-TIP-dPGM.pdf},
  publisher={IEEE},
  abbr={Vision},
  bibtex_show={},
  doi={10.1109/TIP.2024.3357251},
  html={https://ieeexplore.ieee.org/document/10416209},
  url={},   
  selected={false}
}


@inproceedings{2024-AAAI-KGDM,
  title={KGDM: A Diffusion Model to Capture Multiple Relation Semantics for Knowledge Graph Embedding},
  author={Long, Xiao and Zhuang, Liansheng and Li, Aodi and Wang, Jiuchang and Li, Houqiang and Wang, Shafei},
  abstract={nowledge graph embedding (KGE) is an efficient and scalable method for knowledge graph completion. However, most existing KGE methods suffer from the challenge of multiple relation semantics, which often degrades their performance. This is because most KGE methods learn fixed continuous vectors for entities (relations) and make deterministic entity predictions to complete the knowledge graph, which hardly captures multiple relation semantics. To tackle this issue, previous works try to learn complex probabilistic embeddings instead of fixed embeddings but suffer from heavy computational complexity. In contrast, this paper proposes a simple yet efficient framework namely the Knowledge Graph Diffusion Model (KGDM) to capture the multiple relation semantics in prediction. Its key idea is to cast the problem of entity prediction into conditional entity generation. Specifically, KGDM estimates the probabilistic distribution of target entities in prediction through Denoising Diffusion Probabilistic Models (DDPM). To bridge the gap between continuous diffusion models and discrete KGs, two learnable embedding functions are defined to map entities and relation to continuous vectors. To consider connectivity patterns of KGs, a Conditional Entity Denoiser model is introduced to generate target entities conditioned on given entities and relations. Extensive experiments demonstrate that KGDM significantly outperforms existing state-of-the-art methods in three benchmark datasets.},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={8},
  pages ={8850-8858},
  year = {2024},
  month = {},
  address = {},
  pdf ={2024-AAAI-KGDM},
  publisher={AAAI},
  abbr={Vision},
  bibtex_show={true},
  doi={https://doi.org/10.1609/aaai.v38i8.28732},
  html={https://ojs.aaai.org/index.php/AAAI/article/view/28732},
  url={},   
  selected={true}
}

@inproceedings{2023-MMAsia-PbGaR,
  title={Learning a Robust Model with Pseudo Boundaries for Noisy Temporal Action Localization},
  author={Yuan, Xinyi and Zhuang},
  abstract={},
  booktitle={The 5th ACM International Conference on Multimedia in Asia},
  pages ={},
  year = {2023},
  month = {December},
  address = {Taiwan, China},
  pdf ={2023-MMAsia-PbGaR.pdf},
  abbr={Vision},
  bibtex_show={},
  doi={},
  html={},
  url={},   
  selected={false}
}

@inproceedings{2023-MM-CALayoutDM,
  title={Two-stage Content-Aware Layout Generation for Poster Designs},
  author={Chai, Shang and Zhuang, Liansheng and Yan, Fengying and Zhou, Zihan},
  abstract={},
  booktitle={The 31st ACM International Conference on Multimedia},
  pages ={8415-8423},
  year = {2023},
  month = {Oct.},
  address = {Ottawa, Canada},
  pdf ={2023-MM-CALayoutDM.pdf},
  abbr={Vision},
  bibtex_show={},
  doi={},
  html={},
  url={},   
  selected={false}
}

@inproceedings{2023-MM-OSTAL,
  title={Learning Generalized Representation for Open Set Temporal Action Localization},
  author={Hu, Junshan and Zhuang, Liansheng and Dong, Weisong and Ge, Shiming and Wang, Shafei},
  abstract={},
  booktitle={The 31st ACM International Conference on Multimedia},
  pages ={1987-1996},
  year = {2023},
  month = {Oct.},
  address = {Ottawa, Canada},
  pdf ={2023-MM-OSTAL.pdf},
  abbr={Vision},
  bibtex_show={},
  doi={},
  html={},
  url={},   
  selected={false}
}

@inproceedings{2023-CVPR-LayoutDM,
  title={LayoutDM: Transformer-based Diffusion Model for Conditional Layout Generation},
  author={Chai, Shang and Zhuang, Liansheng and Yan, Fengying},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages ={18349-18358},
  year = {2023},
  month = {June},
  address = {Vancouver, BC, Canada},
  pdf ={2023-CVPR-LayoutDM.pdf},
  abbr={Vision},
  bibtex_show={},
  doi={},
  html={},
  url={},   
  selected={false}
}

@inproceedings{2023-IJCNN-MAPF,
  title={Curriculum Learning Based Multi-Agent Path Finding for Complex Enviroments},
  author={Zhao, Cheng and Zhuang, Liansheng and Huang, Yihong and Liu, Haonan},
  booktitle={2023 International Joint Conference on Neural Networks},
  pages ={1-8},
  year = {2023},
  month = {June},
  address = {Gold Coast, Australia},
  pdf ={2023-IJCNN-MAPF.pdf},
  abbr={Vision},
  bibtex_show={},
  doi={},
  html={},
  url={},  
  selected={false}
}

@inproceedings{2023-IJCNN-BSPT,
  title={Bayesian Sharpness-Aware Prompt Tuning for Cross-Domain Few-Shot Learning},
  author={Fan, Shuo and Zhuang, Liansheng and Li, Aodi},
  booktitle={2023 International Joint Conference on Neural Networks},
  pages ={1-7},
  year = {2023},
  month = {June},
  address = {Gold Coast, Australia},
  pdf ={2023-IJCNN-BSPT.pdf},
  abbr={Vision},
   bibtex_show={},
  doi={},
  html={},
  url={},  
  selected={false}
}


@article{2023-TMM-DSKI,
  title={Dual Structural Knowledge Interaction for Domain Adaptation},
  author={Zuo, Yukun and Yao, Hantao and Zhuang, Liansheng and Xu, Changsheng},
  journal={IEEE Transactions on Multimedia},
  volume={25},
  number={},
  pages={9057-9070},
  year={2023},
  pdf={2023-TMM-DSKI.pdf},
  publisher={IEEE},
  abbr={Vision},
   bibtex_show={},
  doi={},
  html={},
  url={},  
  selected={false}
}

@inproceedings{2022-EMNLP-NMPQEM,
  title={Neural-based Mixture Probabilistic Query Embedding for Answering FOL queries on Knowledge Graphs},
  author={Long, Xiao and Zhuang, Liansheng and Li, Aodi and Wang, Shafei and Li, Houqiang},
  booktitle={The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)},
  pages ={3001-3013},
  year = {2022},
  month = {Dec.7-11},
  address = {Abu Dhabi, United Arab Emirates},
  pdf ={2022-EMNLP-NMPQEM.pdf},
  abbr={NLP},
  bibtex_show={},
  doi={},
  html={},
  url={},  
  selected={false}
}



@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  bibtex_show={true},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  selected={true}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schr√∂dinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}
